{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "789edf24",
      "metadata": {},
      "source": [
        "### **Model Deployment and Inference**\n",
        "\n",
        "This notebook validates that the trained **sales prediction pipeline** can be loaded and used to make predictions on new, unseen user input.\n",
        "\n",
        "We load a single artifact:\n",
        "- `models/sales_pipeline_latest.pkl`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecf8c9db",
      "metadata": {},
      "source": [
        "#### **Model Selection Justification (Why ML over LSTM)**\n",
        "\n",
        "We experimented with:\n",
        "1. Machine Learning (LightGBM)\n",
        "2. Time Series Forecasting\n",
        "3. Deep Learning (LSTM)\n",
        "\n",
        "The LightGBM model was selected for deployment because:\n",
        "- Higher validation accuracy (better RMSE/R²)\n",
        "- Instant inference (low latency)\n",
        "- Requires only current business inputs (no 30-day history)\n",
        "- Lightweight and suitable for real-time usage\n",
        "- Easier for business users\n",
        "\n",
        "LSTM requires sequential historical inputs and is slower for real-time business decisions.\n",
        "Therefore, LightGBM is more suitable for production deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45b29bc9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import logging\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6ad05f1",
      "metadata": {},
      "source": [
        "#### **Silencing Warnings**\n",
        "These are not to be removed as they are ok to be present in the system. But in case there is a need of warning then this code we can comment or remove."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c1085b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d73d14eb",
      "metadata": {},
      "source": [
        "#### **Logger Setup**\n",
        "Logs are written to the `logs/` folder. Use these logs to debug long training runs or unexpected behavior; they're helpful for reproducing issues later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "f86d505f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== MODEL DEPLOYMENT AND INFERENCE SAMPLE PROCESS STARTED =====\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(\"logs\"):\n",
        "    os.makedirs(\"logs\")\n",
        "\n",
        "logging.basicConfig(\n",
        "    filename=\"logs/model_deployment_inference.log\",\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
        "    force=True\n",
        ")\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def print_and_log(message, level='info'):\n",
        "    print(message)\n",
        "    if level == 'info':\n",
        "        logger.info(message)\n",
        "    elif level == 'warning':\n",
        "        logger.warning(message)\n",
        "    elif level == 'error':\n",
        "        logger.error(message)\n",
        "    else:\n",
        "        logger.debug(message) \n",
        "              \n",
        "print_and_log(\"===== MODEL DEPLOYMENT AND INFERENCE SAMPLE PROCESS STARTED =====\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf6d7f94",
      "metadata": {},
      "source": [
        "#### **Loading the trained model pipeline(sample)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "9f805eec",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"Loading the trained model pipeline...\")\n",
        "pipeline = joblib.load(\"models/sales_pipeline_latest.pkl\")\n",
        "print_and_log(\"Pipeline loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c736f4f",
      "metadata": {},
      "source": [
        "#### **Creating sample input data for inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "7b37cfb7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample input data created successfully!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>storetype</th>\n",
              "      <th>assortment</th>\n",
              "      <th>stateholiday</th>\n",
              "      <th>customers</th>\n",
              "      <th>competitiondistance</th>\n",
              "      <th>promo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a</td>\n",
              "      <td>c</td>\n",
              "      <td>0</td>\n",
              "      <td>650</td>\n",
              "      <td>450</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  storetype assortment stateholiday  customers  competitiondistance  promo\n",
              "0         a          c            0        650                  450      1"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logger.info(\"Creating sample input data for inference...\")\n",
        "sample_input = pd.DataFrame([{\n",
        "    \"storetype\": \"a\",\n",
        "    \"assortment\": \"c\",\n",
        "    \"stateholiday\": \"0\",\n",
        "    \"customers\": 650,\n",
        "    \"competitiondistance\": 450,\n",
        "    \"promo\": 1\n",
        "}])\n",
        "print_and_log(\"Sample input data created successfully!\")\n",
        "sample_input"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55a87e49",
      "metadata": {},
      "source": [
        "#### **Performing inference using the loaded pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "2a680089",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Store Sales: 6077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Aishwarya Kr Singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"Performing inference using the loaded pipeline...\")\n",
        "prediction = pipeline.predict(sample_input)\n",
        "print_and_log(f\"Predicted Store Sales: {int(prediction[0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94fb1341",
      "metadata": {},
      "source": [
        "\n",
        "### **Summary**\n",
        "#### **Final Summary — Model Deployment and Inference**\n",
        "\n",
        "In this notebook, we validated the deployment readiness of the Rossmann Store Sales Prediction system.\n",
        "\n",
        "The objective was to confirm that the trained model can operate independently of the training notebooks and correctly generate predictions using new unseen input data.\n",
        "\n",
        "\n",
        "#### **What Was Done**\n",
        "\n",
        "1. The final trained machine learning pipeline (`sales_pipeline_latest.pkl`) was loaded.\n",
        "2. A real-world business input scenario was simulated (store conditions provided manually).\n",
        "3. The pipeline automatically performed:\n",
        "   - categorical encoding\n",
        "   - numerical scaling\n",
        "   - feature alignment\n",
        "4. The model generated a predicted sales value successfully.\n",
        "\n",
        "This confirms that the preprocessing and modeling steps are fully integrated inside a single reusable pipeline.\n",
        "\n",
        "\n",
        "#### **Why a Pipeline Was Used**\n",
        "\n",
        "During earlier experiments, the model depended on separate components:\n",
        "- label encoders\n",
        "- scalers\n",
        "- feature transformations\n",
        "\n",
        "This caused deployment issues due to schema mismatch between training and inference.\n",
        "\n",
        "To resolve this, a Scikit-Learn Pipeline was created combining:\n",
        "Preprocessing (ColumnTransformer) + LightGBM Model\n",
        "\n",
        "This ensures:\n",
        "• identical preprocessing during training and prediction  \n",
        "• no manual feature handling during deployment  \n",
        "• reduced risk of errors  \n",
        "• easier integration with applications\n",
        "\n",
        "#### **Model Selection Justification**\n",
        "\n",
        "Multiple approaches were explored:\n",
        "- Machine Learning (LightGBM)\n",
        "- Time Series Forecasting\n",
        "- Deep Learning (LSTM)\n",
        "\n",
        "Although LSTM captured sequential patterns, it required historical sequences and longer inference time.\n",
        "\n",
        "The LightGBM pipeline was selected for deployment because:\n",
        "- better performance on tabular retail data\n",
        "- faster prediction time\n",
        "- requires only current store parameters\n",
        "- suitable for real business users\n",
        "\n",
        "#### **Deployment Readiness**\n",
        "\n",
        "The successful prediction confirms:\n",
        "- model serialization works correctly\n",
        "- preprocessing pipeline functions properly\n",
        "- feature schema consistency is maintained\n",
        "- the system is ready for real-time usage\n",
        "\n",
        "The same pipeline is now integrated into a Streamlit web application (`app.py`) where a user can enter store\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
